{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Document similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO3K8k32o8bBykKIGBiCqqU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivaNavya/Document-similarity/blob/master/Document_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fe5f4PWvV-1",
        "colab_type": "code",
        "outputId": "bcb5138e-3208-45df-ebe1-c1c5760e8815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import string\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soxvUp4lvenm",
        "colab_type": "code",
        "outputId": "0915f355-df1d-41a8-8a47-4d20eaa5ea39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whfn-z2vvhTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.path.abspath(os.getcwd())\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Text analytics')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1BI_4isvnhq",
        "colab_type": "text"
      },
      "source": [
        "**Document cleaning function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmPGCq8lvkH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fileclean(file):\n",
        "        file = open(file, encoding=\"utf8\")\n",
        "        Lines = file.readlines()\n",
        "\n",
        "\n",
        "        #splitting the text file into lines\n",
        "        words=[]\n",
        "        for line in Lines:\n",
        "            a=line.split()\n",
        "            words.append(a)\n",
        "\n",
        "            \n",
        "        #Unlist the nested lists\n",
        "        flat_list=[]\n",
        "        for sublist in words:\n",
        "            for item in sublist:\n",
        "                flat_list.append(item)\n",
        "        #converting words to lowercase\n",
        "        flat_list = [x.lower() for x in flat_list]\n",
        "\n",
        "\n",
        "        #remove stopwords         \n",
        "        filtered_words = [word for word in flat_list if word not in stopwords.words('english')]\n",
        "\n",
        "        #remove the punctuation\n",
        "        #source: https://www.tutorialspoint.com/python/string_translate.htm\n",
        "\n",
        "        list_withoutpunct=[]\n",
        "        b=[]\n",
        "        for item in filtered_words:\n",
        "            b=item.translate(item.maketrans('', '', string.punctuation))\n",
        "            list_withoutpunct.append(b)\n",
        "\n",
        "        # print(str_withoutpunct)\n",
        "\n",
        "        #remove the numbers\n",
        "        numbers=\"1234567890\"\n",
        "        list_withoutnum=[]\n",
        "        c=[]\n",
        "        for item in list_withoutpunct:\n",
        "            c=item.translate(item.maketrans('', '', numbers))\n",
        "            list_withoutnum.append(c)\n",
        "        # print(list_withoutnum)\n",
        "\n",
        "\n",
        "        #remove the whitespace\n",
        "        space= \" \"\n",
        "        blank = \"\"\n",
        "        list_withoutspace=[]\n",
        "        d=[]\n",
        "        for item in list_withoutnum:\n",
        "            if item == space:\n",
        "                list_withoutnum.remove(item)\n",
        "            if item == blank:\n",
        "                list_withoutnum.remove(item)\n",
        "\n",
        "\n",
        "        #removing words with less than 3 length and finding unique words\n",
        "        dict=[]\n",
        "        for word in list_withoutnum:\n",
        "            if len(word)>3:\n",
        "              dict.append(word)\n",
        "\n",
        "        uniqueWords = [] \n",
        "        for i in dict:\n",
        "            if not i in uniqueWords:\n",
        "                    uniqueWords.append(i);    \n",
        "\n",
        "        #using isalpha to remove the symbols if any\n",
        "        list_withoutisalpha=[]\n",
        "\n",
        "        for item in uniqueWords:\n",
        "          if item.isalpha()==True:\n",
        "            list_withoutisalpha.append(item)\n",
        "        #print(list_withoutisalpha)\n",
        "\n",
        "        \n",
        "\n",
        "        return (list_withoutisalpha)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv2hUQpC0Rug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UIUC = fileclean('UIUC.txt')\n",
        "UIC = fileclean('UIC.txt')\n",
        "MIT = fileclean('MIT.txt')\n",
        "UIS = fileclean('UIS.txt')\n",
        "Tesla = fileclean('Tesla.txt')\n",
        "Standford = fileclean('Stanford.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzmkUCDu1qSW",
        "colab_type": "text"
      },
      "source": [
        "**JACCARD SIMILARITY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq7PWwRf32YQ",
        "colab_type": "code",
        "outputId": "d3a3a56e-1854-4bcf-a56b-e0bdef486ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tokenized_documents = [UIUC,UIC]\n",
        "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
        "a = len(UIC) + len(UIUC)\n",
        "print(a)\n",
        "\n",
        "print(len(all_tokens_set))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3444\n",
            "2799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnbkWkK41w-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding jaccard similarity\n",
        "\n",
        "def jaccard_similarity(query, document):\n",
        "    intersection = set(query).intersection(set(document))\n",
        "    union = set(query).union(set(document))\n",
        "    return len(intersection)/len(union)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiUtmZZo8TJf",
        "colab_type": "text"
      },
      "source": [
        "**Jaccard similarity between UIC and the other documents**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vDB_ssw5L_b",
        "colab_type": "code",
        "outputId": "1950498d-9ac0-4e73-f90f-3e99904f8782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "jac_UIUC = jaccard_similarity(UIC,UIUC)\n",
        "jac_MIT = jaccard_similarity(UIC,MIT)\n",
        "jac_UIS = jaccard_similarity(UIC,UIS)\n",
        "jac_Tesla = jaccard_similarity(UIC,Tesla)\n",
        "jac_Stanford = jaccard_similarity(UIC,Standford)\n",
        "\n",
        "list_jac = [jac_UIUC,jac_MIT,jac_UIS,jac_Tesla,jac_Stanford]\n",
        "\n",
        "df = pd.DataFrame(list_jac)\n",
        "df1 =df.T\n",
        "df1.rename(index={0: 'UIC'}, inplace=True)\n",
        "df1.columns = ['UIUC', 'MIT','UIS','Tesla','Stanford']\n",
        "\n",
        "df1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UIUC</th>\n",
              "      <th>MIT</th>\n",
              "      <th>UIS</th>\n",
              "      <th>Tesla</th>\n",
              "      <th>Stanford</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>UIC</th>\n",
              "      <td>0.230439</td>\n",
              "      <td>0.167174</td>\n",
              "      <td>0.196798</td>\n",
              "      <td>0.138295</td>\n",
              "      <td>0.20869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         UIUC       MIT       UIS     Tesla  Stanford\n",
              "UIC  0.230439  0.167174  0.196798  0.138295   0.20869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FgtGSLdKJvk",
        "colab_type": "text"
      },
      "source": [
        "**COSINE SIMILARITY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7O_9ZIay-0B",
        "colab_type": "code",
        "outputId": "4ab4e596-4bf0-445f-c135-7ca09367b296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "\n",
        "\n",
        "text1 = open(r\"UIC.txt\",\"rt\", encoding=\"utf8\")\n",
        "UIC_txt=text1.read()\n",
        "text1.close()\n",
        "\n",
        "text2 = open(r\"UIUC.txt\",\"rt\",encoding=\"utf8\")\n",
        "UIUC_txt= text2.read()\n",
        "text2.close()\n",
        "\n",
        "text3 = open(r\"MIT.txt\",\"rt\",encoding=\"utf8\")\n",
        "MIT_txt= text3.read()\n",
        "text3.close()\n",
        "\n",
        "text4 = open(r\"UIS.txt\",\"rt\",encoding=\"utf8\")\n",
        "UIS_txt= text4.read()\n",
        "text4.close()\n",
        "\n",
        "text5 = open(r\"Tesla.txt\",\"rt\",encoding=\"utf8\")\n",
        "Tesla_txt= text5.read()\n",
        "text5.close()\n",
        "\n",
        "text6 = open(r\"Stanford.txt\",\"rt\",encoding=\"utf8\")\n",
        "Stanford_txt= text6.read()\n",
        "text6.close()\n",
        " \n",
        "documents = [UIC_txt,UIUC_txt,MIT_txt,UIS_txt,Tesla_txt,Stanford_txt]\n",
        "\n",
        "# Create the Document Term Matrix\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "count_vectorizer = CountVectorizer()\n",
        "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
        "doc_term_matrix = sparse_matrix.todense()\n",
        "df = pd.DataFrame(doc_term_matrix, \n",
        "                  columns=count_vectorizer.get_feature_names(), \n",
        "                  index=['UIC', 'UIUC','MIT','UIS','Tesla','Stanford'])\n",
        "\n",
        "\n",
        "#Compute Cosine Similarity\n",
        "\n",
        "cos_sim = cosine_similarity(df,df)[0]\n",
        "cos_sim = pd.DataFrame(cos_sim)\n",
        "\n",
        "df2 =cos_sim.T\n",
        "df2.rename(index={0: 'UIC'}, inplace=True)\n",
        "df2.columns = ['UIC','UIUC', 'MIT','UIS','Tesla','Stanford']\n",
        "df2\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UIC</th>\n",
              "      <th>UIUC</th>\n",
              "      <th>MIT</th>\n",
              "      <th>UIS</th>\n",
              "      <th>Tesla</th>\n",
              "      <th>Stanford</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>UIC</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.92725</td>\n",
              "      <td>0.817371</td>\n",
              "      <td>0.827752</td>\n",
              "      <td>0.664295</td>\n",
              "      <td>0.818043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     UIC     UIUC       MIT       UIS     Tesla  Stanford\n",
              "UIC  1.0  0.92725  0.817371  0.827752  0.664295  0.818043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}